#0  at::native::cpublas::(anonymous namespace)::gemm_notrans_<float, float> (m=16, n=4, k=32, alpha=1, a=0x555557d4c400, lda=16, b=0x555557d43480, ldb=32, beta=0, c=0x555557d43800, ldc=16)
    at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/native/cpu/BlasKernel.cpp:71
#1  0x00007fffeb824cb0 in at::native::cpublas::(anonymous namespace)::gemm_core_<float, float> (transa=at::native::TransposeType::NoTranspose, transb=at::native::TransposeType::NoTranspose, m=16, 
    n=4, k=32, alpha=1, a=0x555557d4c400, lda=16, b=0x555557d43480, ldb=32, beta=0, c=0x555557d43800, ldc=16)
    at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/native/cpu/BlasKernel.cpp:251
#2  0x00007fffeb821005 in operator() (__closure=0x7fffffffbf50) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/native/cpu/BlasKernel.cpp:286
#3  0x00007fffeb821d57 in operator() (__closure=0x7fffffffc080) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/native/cpu/BlasKernel.cpp:286
#4  0x00007fffeb822516 in at::native::cpublas::(anonymous namespace)::cpublas_gemm_impl (type=c10::ScalarType::Float, transa=at::native::TransposeType::NoTranspose, 
    transb=at::native::TransposeType::NoTranspose, m=16, n=4, k=32, alpha=..., a=0x555557d4c400, lda=16, b=0x555557d43480, ldb=32, beta=..., c=0x555557d43800, ldc=16)
    at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/native/cpu/BlasKernel.cpp:286
#5  0x00007fffe3f533af in at::native::DispatchStub<void (*)(c10::ScalarType, at::native::TransposeType, at::native::TransposeType, long, long, long, c10::Scalar const&, void const*, long, void const*, long, c10::Scalar const&, void*, long), at::native::cpublas::gemm_stub>::operator()<c10::ScalarType const&, at::native::TransposeType&, at::native::TransposeType&, long&, long&, long&, float const&, float const*&, long&, float const*&, long&, float const&, float*&, long&> (this=0x7ffff7bdcae0 <at::native::cpublas::gemm_stub>, device_type=c10::DeviceType::CPU)
    at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/native/DispatchStub.h:158
#6  0x00007fffe3f4fe02 in at::native::cpublas::gemm (transa=at::native::TransposeType::NoTranspose, transb=at::native::TransposeType::NoTranspose, m=16, n=4, k=32, alpha=1, a=0x555557d4c400, lda=16, 
    b=0x555557d43480, ldb=32, beta=0, c=0x555557d43800, ldc=16) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/native/CPUBlas.cpp:199
#7  0x00007fffe40c47ba in operator() (__closure=0x7fffffffc420) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:1513
#8  0x00007fffe40c5880 in operator() (__closure=0x7fffffffc640) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:1513
#9  0x00007fffe40c6f27 in at::native::addmm_impl_cpu_ (result=..., self=..., m1=..., m2=..., beta=..., alpha=...)
    at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:1513
#10 0x00007fffe40c80d1 in at::native::structured_mm_out_cpu::impl (this=0x7fffffffc7f0, self=..., mat2=..., result=...)
    at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:1617
#11 0x00007fffe5b0cdd6 in at::(anonymous namespace)::wrapper_CPU_mm (self=..., mat2=...) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch-build/aten/src/ATen/RegisterCPU.cpp:8643
#12 0x00007fffe5ceb6b6 in c10::impl::detail::WrapFunctionIntoFunctor_<c10::CompileTimeFunctionPointer<at::Tensor(const at::Tensor&, const at::Tensor&), at::(anonymous namespace)::wrapper_CPU_mm>, at::Tensor, c10::guts::typelist::typelist<const at::Tensor&, const at::Tensor&> >::operator() (args#1=..., args#0=..., this=0x55555604ba60)
    at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/core/boxing/impl/WrapFunctionIntoFunctor.h:13
#13 c10::impl::wrap_kernel_functor_unboxed_<c10::impl::detail::WrapFunctionIntoFunctor_<c10::CompileTimeFunctionPointer<at::Tensor(const at::Tensor&, const at::Tensor&), at::(anonymous namespace)::wrapper_CPU_mm>, at::Tensor, c10::guts::typelist::typelist<const at::Tensor&, const at::Tensor&> >, at::Tensor(const at::Tensor&, const at::Tensor&)>::call(c10::OperatorKernel *, c10::DispatchKeySet, const at::Tensor &, const at::Tensor &) (functor=0x55555604ba60, args#0=..., args#1=...)
    at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h:468
#14 0x00007fffe4dcf95a in c10::callUnboxedKernelFunction<at::Tensor, at::Tensor const&, at::Tensor const&> (
    unboxed_kernel_func=0x7fffe5ceb61d <c10::impl::wrap_kernel_functor_unboxed_<c10::impl::detail::WrapFunctionIntoFunctor_<c10::CompileTimeFunctionPointer<at::Tensor(const at::Tensor&, const at::Tensor&), at::(anonymous namespace)::wrapper_CPU_mm>, at::Tensor, c10::guts::typelist::typelist<const at::Tensor&, const at::Tensor&> >, at::Tensor(const at::Tensor&, const at::Tensor&)>::call(c10::OperatorKernel *, c10::DispatchKeySet, const at::Tensor &, const at::Tensor &)>, functor=0x55555604ba60, dispatchKeySet=...)
    at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/core/boxing/KernelFunction_impl.h:50
#15 0x00007fffe4c7155f in c10::KernelFunction::call<at::Tensor, at::Tensor const&, at::Tensor const&> (dispatchKeySet=..., opHandle=..., this=0x5555555a6d48)
    at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/core/boxing/KernelFunction_impl.h:103
#16 c10::Dispatcher::redispatch<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, c10::DispatchKeySet, at::Tensor const&, at::Tensor const&) const (this=0x7ffff7bd8040 <c10::Dispatcher::realSingleton()::_singleton>, op=..., currentDispatchKeySet=...)
    at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/core/dispatch/Dispatcher.h:690
#17 0x00007fffe561205e in c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)>::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&) const (args#1=..., 
    args#0=..., currentDispatchKeySet=..., this=<optimized out>) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/core/dispatch/Dispatcher.h:526
#18 at::_ops::mm::redispatch (dispatchKeySet=..., self=..., mat2=...) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch-build/aten/src/ATen/Operators_3.cpp:3896
#19 0x00007fffe86c7c17 in at::redispatch::mm (dispatchKeySet=..., self=..., mat2=...) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch-build/aten/src/ATen/RedispatchFunctions.h:5112
#20 0x00007fffe85dab1e in operator() (__closure=0x7fffffffcc90) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12504
#21 0x00007fffe85db28d in torch::autograd::VariableType::(anonymous namespace)::mm (ks=..., self=..., mat2=...)
    at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:12505
#22 0x00007fffe86913ee in c10::impl::detail::WrapFunctionIntoFunctor_<c10::CompileTimeFunctionPointer<at::Tensor(c10::DispatchKeySet, const at::Tensor&, const at::Tensor&), torch::autograd::VariableType::(anonymous namespace)::mm>, at::Tensor, c10::guts::typelist::typelist<c10::DispatchKeySet, const at::Tensor&, const at::Tensor&> >::operator() (args#2=..., args#1=..., args#0=..., 
    this=0x5555574f7370) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/core/boxing/impl/WrapFunctionIntoFunctor.h:13
#23 c10::impl::wrap_kernel_functor_unboxed_<c10::impl::detail::WrapFunctionIntoFunctor_<c10::CompileTimeFunctionPointer<at::Tensor(c10::DispatchKeySet, const at::Tensor&, const at::Tensor&), torch::autograd::VariableType::(anonymous namespace)::mm>, at::Tensor, c10::guts::typelist::typelist<c10::DispatchKeySet, const at::Tensor&, const at::Tensor&> >, at::Tensor(c10::DispatchKeySet, const at::Tensor&, const at::Tensor&)>::call(c10::OperatorKernel *, c10::DispatchKeySet, const at::Tensor &, const at::Tensor &) (functor=0x5555574f7370, dispatchKeySet=..., args#0=..., args#1=...)
    at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h:485
#24 0x00007fffe4dcf95a in c10::callUnboxedKernelFunction<at::Tensor, at::Tensor const&, at::Tensor const&> (
    unboxed_kernel_func=0x7fffe8691339 <c10::impl::wrap_kernel_functor_unboxed_<c10::impl::detail::WrapFunctionIntoFunctor_<c10::CompileTimeFunctionPointer<at::Tensor(c10::DispatchKeySet, const at::Tensor&, const at::Tensor&), torch::autograd::VariableType::(anonymous namespace)::mm>, at::Tensor, c10::guts::typelist::typelist<c10::DispatchKeySet, const at::Tensor&, const at::Tensor&> >, at::Tensor(c10::DispatchKeySet, const at::Tensor&, const at::Tensor&)>::call(c10::OperatorKernel *, c10::DispatchKeySet, const at::Tensor &, const at::Tensor &)>, functor=0x5555574f7370, dispatchKeySet=...) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/core/boxing/KernelFunction_impl.h:50
#25 0x00007fffe5611e16 in c10::KernelFunction::call<at::Tensor, at::Tensor const&, at::Tensor const&> (dispatchKeySet=..., opHandle=..., this=0x5555555a7728) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/core/boxing/KernelFunction_impl.h:103
#26 c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const (op=..., this=0x7ffff7bd8040 <c10::Dispatcher::realSingleton()::_singleton>) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/core/dispatch/Dispatcher.h:673
#27 c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)>::call(at::Tensor const&, at::Tensor const&) const (args#1=..., args#0=..., this=<optimized out>) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/core/dispatch/Dispatcher.h:521
#28 at::_ops::mm::call (self=..., mat2=...) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch-build/aten/src/ATen/Operators_3.cpp:3889
#29 0x00007fffe40de0ea in at::Tensor::mm (this=0x7fffffffd528, mat2=...) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch-build/aten/src/ATen/core/TensorBody.h:2991
#30 0x00007fffe40cbe51 in at::native::_matmul_impl (out=..., tensor1=..., tensor2=...) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:1996
#31 0x00007fffe40cd413 in at::native::matmul (tensor1=..., tensor2=...) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:2144
#32 0x00007fffe61bc23c in at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__matmul (self=..., other=...) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch-build/aten/src/ATen/RegisterCompositeImplicitAutograd.cpp:2753
#33 0x00007fffe62c11dc in c10::impl::detail::WrapFunctionIntoFunctor_<c10::CompileTimeFunctionPointer<at::Tensor(const at::Tensor&, const at::Tensor&), at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__matmul>, at::Tensor, c10::guts::typelist::typelist<const at::Tensor&, const at::Tensor&> >::operator() (args#1=..., args#0=..., this=0x555556901550) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/core/boxing/impl/WrapFunctionIntoFunctor.h:13
#34 c10::impl::wrap_kernel_functor_unboxed_<c10::impl::detail::WrapFunctionIntoFunctor_<c10::CompileTimeFunctionPointer<at::Tensor(const at::Tensor&, const at::Tensor&), at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__matmul>, at::Tensor, c10::guts::typelist::typelist<const at::Tensor&, const at::Tensor&> >, at::Tensor(const at::Tensor&, const at::Tensor&)>::call(c10::OperatorKernel *, c10::DispatchKeySet, const at::Tensor &, const at::Tensor &) (functor=0x555556901550, args#0=..., args#1=...) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h:468
#35 0x00007fffe4dcf95a in c10::callUnboxedKernelFunction<at::Tensor, at::Tensor const&, at::Tensor const&> (unboxed_kernel_func=0x7fffe62c1143 <c10::impl::wrap_kernel_functor_unboxed_<c10::impl::detail::WrapFunctionIntoFunctor_<c10::CompileTimeFunctionPointer<at::Tensor(const at::Tensor&, const at::Tensor&), at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__matmul>, at::Tensor, c10::guts::typelist::typelist<const at::Tensor&, const at::Tensor&> >, at::Tensor(const at::Tensor&, const at::Tensor&)>::call(c10::OperatorKernel *, c10::DispatchKeySet, const at::Tensor &, const at::Tensor &)>, functor=0x555556901550, dispatchKeySet=...) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/core/boxing/KernelFunction_impl.h:50
#36 0x00007fffe5898682 in c10::KernelFunction::call<at::Tensor, at::Tensor const&, at::Tensor const&> (dispatchKeySet=..., opHandle=..., this=0x55555565b9d8) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/core/boxing/KernelFunction_impl.h:103
#37 c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const (op=..., this=0x7ffff7bd8040 <c10::Dispatcher::realSingleton()::_singleton>) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/core/dispatch/Dispatcher.h:673
#38 c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)>::call(at::Tensor const&, at::Tensor const&) const (args#1=..., args#0=..., this=<optimized out>) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch/aten/src/ATen/core/dispatch/Dispatcher.h:521
#39 at::_ops::matmul::call (self=..., other=...) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch-build/aten/src/ATen/Operators_4.cpp:3052
#40 0x000055555555aadf in at::matmul (self=..., other=...) at /home/alexey/YSDA/YSDA-CPU-inference/cpp/pytorch-install/include/ATen/ops/matmul.h:27
#41 0x00005555555578f4 in main () at /home/alexey/YSDA/YSDA-CPU-inference/cpp/src/pytorch.cpp:17
