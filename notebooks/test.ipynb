{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "import torch.multiprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.multiprocessing.set_sharing_strategy('file_system')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.vit_b_16(weights=torchvision.models.ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "model.eval()\n",
    "transforms = torchvision.models.ViT_B_16_Weights.IMAGENET1K_V1.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../imagenet1000.txt', 'r') as fopen:\n",
    "    lines = fopen.readlines()\n",
    "\n",
    "def process_classes(line: str):\n",
    "    splitted = line.strip().removeprefix('{').removesuffix(',').split(':')\n",
    "    return (int(splitted[0]), splitted[1].strip().strip('\\''))\n",
    "\n",
    "orig_classes = dict(map(process_classes, lines))\n",
    "\n",
    "imagenette_classes = dict(enumerate(['tench', 'English springer', 'cassette player', 'chain saw', 'church', 'French horn', 'garbage truck', 'gas pump', 'golf ball', 'parachute']))\n",
    "\n",
    "for k, v in imagenette_classes.items():\n",
    "    for k1, v1 in orig_classes.items():\n",
    "        if v in v1:\n",
    "            imagenette_classes[k] = k1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, datasource, transforms: callable, ramming: bool = False):\n",
    "        super().__init__()\n",
    "        self.transforms = transforms\n",
    "        self.ramming = ramming\n",
    "        if ramming:\n",
    "            ram_data = []\n",
    "            for i in range(len(datasource)):\n",
    "                data = datasource[i]\n",
    "                ram_data.append({'image': data['image'], 'label': data['label']})\n",
    "            self.datasource = ram_data\n",
    "        else:\n",
    "            self.datasource = datasource\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.datasource)\n",
    "\n",
    "    def __getitem__(self, index: int) -> torch.Tensor:\n",
    "        data = self.datasource[index]\n",
    "        image, label = data['image'], data['label']\n",
    "        if image.mode != 'RGB':\n",
    "            image = Image.fromarray(np.array(image)[..., None].repeat(3, -1))\n",
    "        return self.transforms(image), imagenette_classes[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenette_train = load_dataset('frgfm/imagenette', '320px', split='train')\n",
    "imagenette_valid = load_dataset('frgfm/imagenette', '320px', split='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tiny_imagenet_train = load_dataset('Maysee/tiny-imagenet', split='train')\n",
    "tiny_imagenet_valid = load_dataset('Maysee/tiny-imagenet', split='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 1\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset = Dataset(datasource=tiny_imagenet_train, transforms=transforms())\n",
    "tf = transforms()\n",
    "trainset = Dataset(datasource=imagenette_train, transforms=tf)\n",
    "validset = Dataset(datasource=imagenette_valid, transforms=tf, ramming=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(validset, num_workers=num_workers, batch_size=batch_size, shuffle=False)\n",
    "# valid_dataloader = torch.utils.data.DataLoader(validset, num_workers=num_workers, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nbytes(model: torch.nn.Module):\n",
    "    n = 0\n",
    "    for p in model.parameters():\n",
    "        n += p.nbytes\n",
    "\n",
    "    return n / 1024 ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330.2294006347656"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbytes(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2b90354c50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from itertools import product\n",
    "from torch.ao.quantization import get_default_qconfig_mapping\n",
    "from torch.quantization.quantize_fx import prepare_fx, convert_fx\n",
    "import gc\n",
    "from contextlib import nullcontext\n",
    "from timeit import timeit\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, top_k_accuracy_score\n",
    "import datetime\n",
    "\n",
    "def fix_seed(worker_id=0, seed=0xBADCAFE):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "fix_seed()\n",
    "\n",
    "torch_generator = torch.Generator()\n",
    "torch_generator.manual_seed(0xBADCAFFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_inputs = [validset[i][0] for i in range(len(validset) // 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "matmul_precision = ['medium', 'high', 'highest']\n",
    "quantization = ['None', 'x86', 'fbgemm']\n",
    "mixed_precision = ['']\n",
    "batch_sizes = [1, 4]\n",
    "num_workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, valid_dataloader, limit=2**32):\n",
    "    T = 0.0\n",
    "    Y = []\n",
    "    Y_hat = []\n",
    "    for i, (x, y) in enumerate(valid_dataloader):\n",
    "        if i >= limit:\n",
    "            break\n",
    "        Y.append(y.ravel())\n",
    "        start = time.time()\n",
    "        y_hat = model(x)\n",
    "        end = time.time()\n",
    "        Y_hat.append(y_hat.argmax(-1))\n",
    "        T += end - start\n",
    "    return accuracy_score(np.array(Y).ravel(), np.array(Y_hat).ravel()), T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]STAGE:2023-10-12 19:12:40 82527:82527 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2023-10-12 19:12:43 82527:82527 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2023-10-12 19:12:43 82527:82527 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n",
      "1it [00:06,  6.92s/it]STAGE:2023-10-12 19:12:47 82527:82527 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2023-10-12 19:12:50 82527:82527 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2023-10-12 19:12:50 82527:82527 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n",
      "2it [00:14,  7.23s/it]/home/alexey/.local/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
      "  torch.has_cuda,\n",
      "/home/alexey/.local/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'\n",
      "  torch.has_cudnn,\n",
      "/home/alexey/.local/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  torch.has_mps,\n",
      "/home/alexey/.local/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'\n",
      "  torch.has_mkldnn,\n",
      "/home/alexey/.local/lib/python3.10/site-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "/home/alexey/.local/lib/python3.10/site-packages/torch/ao/quantization/observer.py:1207: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n",
      "STAGE:2023-10-12 19:12:57 82527:82527 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2023-10-12 19:13:00 82527:82527 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2023-10-12 19:13:00 82527:82527 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n",
      "3it [00:24,  8.58s/it]STAGE:2023-10-12 19:13:07 82527:82527 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2023-10-12 19:13:10 82527:82527 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2023-10-12 19:13:10 82527:82527 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n",
      "4it [00:34,  9.21s/it]STAGE:2023-10-12 19:13:18 82527:82527 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2023-10-12 19:13:21 82527:82527 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2023-10-12 19:13:21 82527:82527 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n",
      "5it [00:45,  9.88s/it]STAGE:2023-10-12 19:13:29 82527:82527 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2023-10-12 19:13:33 82527:82527 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2023-10-12 19:13:33 82527:82527 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n",
      "6it [00:57,  9.53s/it]\n"
     ]
    }
   ],
   "source": [
    "limit = 16\n",
    "T = {}\n",
    "date_time = datetime.datetime.now()\n",
    "accuracy = {}\n",
    "with torch.no_grad():\n",
    "    with open(f'profiling{date_time}.txt', 'w+') as fopen:\n",
    "        for prec, quant, bs in tqdm(product(matmul_precision, quantization, batch_sizes)):\n",
    "            valid_dataloader = torch.utils.data.DataLoader(validset, num_workers=num_workers, \n",
    "                                                        batch_size=batch_size, shuffle=True, \n",
    "                                                        worker_init_fn=fix_seed, generator=torch_generator)\n",
    "            model = torchvision.models.vit_b_16(weights=torchvision.models.ViT_B_16_Weights.IMAGENET1K_V1).eval()\n",
    "            torch.set_float32_matmul_precision(prec)\n",
    "            if quant != 'None':\n",
    "                torch.backends.quantized.engine = quant\n",
    "                qconfig_mapping = get_default_qconfig_mapping(quant)\n",
    "                prepared_model = prepare_fx(model, qconfig_mapping, example_inputs=examples_inputs)\n",
    "                model = convert_fx(prepared_model)\n",
    "            key  = '_'.join(map(str, [prec, quant, bs, round(nbytes(model))]))\n",
    "            with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "                for i, (x, y) in enumerate(valid_dataloader):\n",
    "                    with record_function(\"model_inference\"):\n",
    "                        if i >= limit:\n",
    "                            break\n",
    "                        model(x)\n",
    "            fopen.write(f'{key}\\n')\n",
    "            fopen.write(prof.key_averages().table(sort_by=\"cpu_time_total\"))\n",
    "\n",
    "            # acc, t = run_epoch(model, valid_dataloader, limit)\n",
    "            \n",
    "            # T[key] = np.round(t / (min(limit, len(valid_dataloader)) * bs), 3)\n",
    "            # accuracy[key] = np.round(acc, 3)\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = next(model.parameters()).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['class_token', 'conv_proj_input_scale_0', 'conv_proj_input_zero_point_0', '_scale_2', '_zero_point_2', 'encoder_scale_0', 'encoder_zero_point_0', 'encoder_scale_1', 'encoder_zero_point_1', 'encoder_layers_encoder_layer_0_scale_0', 'encoder_layers_encoder_layer_0_zero_point_0', 'encoder_layers_encoder_layer_0_scale_1', 'encoder_layers_encoder_layer_0_zero_point_1', 'encoder_layers_encoder_layer_0_mlp_1_scale_0', 'encoder_layers_encoder_layer_0_mlp_1_zero_point_0', 'encoder_layers_encoder_layer_0_scale_2', 'encoder_layers_encoder_layer_0_zero_point_2', 'encoder_layers_encoder_layer_1_scale_0', 'encoder_layers_encoder_layer_1_zero_point_0', 'encoder_layers_encoder_layer_1_scale_1', 'encoder_layers_encoder_layer_1_zero_point_1', 'encoder_layers_encoder_layer_1_mlp_1_scale_0', 'encoder_layers_encoder_layer_1_mlp_1_zero_point_0', 'encoder_layers_encoder_layer_1_scale_2', 'encoder_layers_encoder_layer_1_zero_point_2', 'encoder_layers_encoder_layer_2_scale_0', 'encoder_layers_encoder_layer_2_zero_point_0', 'encoder_layers_encoder_layer_2_scale_1', 'encoder_layers_encoder_layer_2_zero_point_1', 'encoder_layers_encoder_layer_2_mlp_1_scale_0', 'encoder_layers_encoder_layer_2_mlp_1_zero_point_0', 'encoder_layers_encoder_layer_2_scale_2', 'encoder_layers_encoder_layer_2_zero_point_2', 'encoder_layers_encoder_layer_3_scale_0', 'encoder_layers_encoder_layer_3_zero_point_0', 'encoder_layers_encoder_layer_3_scale_1', 'encoder_layers_encoder_layer_3_zero_point_1', 'encoder_layers_encoder_layer_3_mlp_1_scale_0', 'encoder_layers_encoder_layer_3_mlp_1_zero_point_0', 'encoder_layers_encoder_layer_3_scale_2', 'encoder_layers_encoder_layer_3_zero_point_2', 'encoder_layers_encoder_layer_4_scale_0', 'encoder_layers_encoder_layer_4_zero_point_0', 'encoder_layers_encoder_layer_4_scale_1', 'encoder_layers_encoder_layer_4_zero_point_1', 'encoder_layers_encoder_layer_4_mlp_1_scale_0', 'encoder_layers_encoder_layer_4_mlp_1_zero_point_0', 'encoder_layers_encoder_layer_4_scale_2', 'encoder_layers_encoder_layer_4_zero_point_2', 'encoder_layers_encoder_layer_5_scale_0', 'encoder_layers_encoder_layer_5_zero_point_0', 'encoder_layers_encoder_layer_5_scale_1', 'encoder_layers_encoder_layer_5_zero_point_1', 'encoder_layers_encoder_layer_5_mlp_1_scale_0', 'encoder_layers_encoder_layer_5_mlp_1_zero_point_0', 'encoder_layers_encoder_layer_5_scale_2', 'encoder_layers_encoder_layer_5_zero_point_2', 'encoder_layers_encoder_layer_6_scale_0', 'encoder_layers_encoder_layer_6_zero_point_0', 'encoder_layers_encoder_layer_6_scale_1', 'encoder_layers_encoder_layer_6_zero_point_1', 'encoder_layers_encoder_layer_6_mlp_1_scale_0', 'encoder_layers_encoder_layer_6_mlp_1_zero_point_0', 'encoder_layers_encoder_layer_6_scale_2', 'encoder_layers_encoder_layer_6_zero_point_2', 'encoder_layers_encoder_layer_7_scale_0', 'encoder_layers_encoder_layer_7_zero_point_0', 'encoder_layers_encoder_layer_7_scale_1', 'encoder_layers_encoder_layer_7_zero_point_1', 'encoder_layers_encoder_layer_7_mlp_1_scale_0', 'encoder_layers_encoder_layer_7_mlp_1_zero_point_0', 'encoder_layers_encoder_layer_7_scale_2', 'encoder_layers_encoder_layer_7_zero_point_2', 'encoder_layers_encoder_layer_8_scale_0', 'encoder_layers_encoder_layer_8_zero_point_0', 'encoder_layers_encoder_layer_8_scale_1', 'encoder_layers_encoder_layer_8_zero_point_1', 'encoder_layers_encoder_layer_8_mlp_1_scale_0', 'encoder_layers_encoder_layer_8_mlp_1_zero_point_0', 'encoder_layers_encoder_layer_8_scale_2', 'encoder_layers_encoder_layer_8_zero_point_2', 'encoder_layers_encoder_layer_9_scale_0', 'encoder_layers_encoder_layer_9_zero_point_0', 'encoder_layers_encoder_layer_9_scale_1', 'encoder_layers_encoder_layer_9_zero_point_1', 'encoder_layers_encoder_layer_9_mlp_1_scale_0', 'encoder_layers_encoder_layer_9_mlp_1_zero_point_0', 'encoder_layers_encoder_layer_9_scale_2', 'encoder_layers_encoder_layer_9_zero_point_2', 'encoder_layers_encoder_layer_10_scale_0', 'encoder_layers_encoder_layer_10_zero_point_0', 'encoder_layers_encoder_layer_10_scale_1', 'encoder_layers_encoder_layer_10_zero_point_1', 'encoder_layers_encoder_layer_10_mlp_1_scale_0', 'encoder_layers_encoder_layer_10_mlp_1_zero_point_0', 'encoder_layers_encoder_layer_10_scale_2', 'encoder_layers_encoder_layer_10_zero_point_2', 'encoder_layers_encoder_layer_11_scale_0', 'encoder_layers_encoder_layer_11_zero_point_0', 'encoder_layers_encoder_layer_11_scale_1', 'encoder_layers_encoder_layer_11_zero_point_1', 'encoder_layers_encoder_layer_11_mlp_1_scale_0', 'encoder_layers_encoder_layer_11_mlp_1_zero_point_0', 'encoder_layers_encoder_layer_11_scale_2', 'encoder_layers_encoder_layer_11_zero_point_2', '_scale_4', '_zero_point_4', 'conv_proj.weight', 'conv_proj.bias', 'conv_proj.scale', 'conv_proj.zero_point', 'encoder.pos_embedding', 'encoder.layers.encoder_layer_0.ln_1.weight', 'encoder.layers.encoder_layer_0.ln_1.bias', 'encoder.layers.encoder_layer_0.ln_1.scale', 'encoder.layers.encoder_layer_0.ln_1.zero_point', 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_0.ln_2.weight', 'encoder.layers.encoder_layer_0.ln_2.bias', 'encoder.layers.encoder_layer_0.ln_2.scale', 'encoder.layers.encoder_layer_0.ln_2.zero_point', 'encoder.layers.encoder_layer_0.mlp.0.scale', 'encoder.layers.encoder_layer_0.mlp.0.zero_point', 'encoder.layers.encoder_layer_0.mlp.0._packed_params.dtype', 'encoder.layers.encoder_layer_0.mlp.0._packed_params._packed_params', 'encoder.layers.encoder_layer_0.mlp.3.scale', 'encoder.layers.encoder_layer_0.mlp.3.zero_point', 'encoder.layers.encoder_layer_0.mlp.3._packed_params.dtype', 'encoder.layers.encoder_layer_0.mlp.3._packed_params._packed_params', 'encoder.layers.encoder_layer_1.ln_1.weight', 'encoder.layers.encoder_layer_1.ln_1.bias', 'encoder.layers.encoder_layer_1.ln_1.scale', 'encoder.layers.encoder_layer_1.ln_1.zero_point', 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_1.ln_2.weight', 'encoder.layers.encoder_layer_1.ln_2.bias', 'encoder.layers.encoder_layer_1.ln_2.scale', 'encoder.layers.encoder_layer_1.ln_2.zero_point', 'encoder.layers.encoder_layer_1.mlp.0.scale', 'encoder.layers.encoder_layer_1.mlp.0.zero_point', 'encoder.layers.encoder_layer_1.mlp.0._packed_params.dtype', 'encoder.layers.encoder_layer_1.mlp.0._packed_params._packed_params', 'encoder.layers.encoder_layer_1.mlp.3.scale', 'encoder.layers.encoder_layer_1.mlp.3.zero_point', 'encoder.layers.encoder_layer_1.mlp.3._packed_params.dtype', 'encoder.layers.encoder_layer_1.mlp.3._packed_params._packed_params', 'encoder.layers.encoder_layer_2.ln_1.weight', 'encoder.layers.encoder_layer_2.ln_1.bias', 'encoder.layers.encoder_layer_2.ln_1.scale', 'encoder.layers.encoder_layer_2.ln_1.zero_point', 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_2.ln_2.weight', 'encoder.layers.encoder_layer_2.ln_2.bias', 'encoder.layers.encoder_layer_2.ln_2.scale', 'encoder.layers.encoder_layer_2.ln_2.zero_point', 'encoder.layers.encoder_layer_2.mlp.0.scale', 'encoder.layers.encoder_layer_2.mlp.0.zero_point', 'encoder.layers.encoder_layer_2.mlp.0._packed_params.dtype', 'encoder.layers.encoder_layer_2.mlp.0._packed_params._packed_params', 'encoder.layers.encoder_layer_2.mlp.3.scale', 'encoder.layers.encoder_layer_2.mlp.3.zero_point', 'encoder.layers.encoder_layer_2.mlp.3._packed_params.dtype', 'encoder.layers.encoder_layer_2.mlp.3._packed_params._packed_params', 'encoder.layers.encoder_layer_3.ln_1.weight', 'encoder.layers.encoder_layer_3.ln_1.bias', 'encoder.layers.encoder_layer_3.ln_1.scale', 'encoder.layers.encoder_layer_3.ln_1.zero_point', 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_3.ln_2.weight', 'encoder.layers.encoder_layer_3.ln_2.bias', 'encoder.layers.encoder_layer_3.ln_2.scale', 'encoder.layers.encoder_layer_3.ln_2.zero_point', 'encoder.layers.encoder_layer_3.mlp.0.scale', 'encoder.layers.encoder_layer_3.mlp.0.zero_point', 'encoder.layers.encoder_layer_3.mlp.0._packed_params.dtype', 'encoder.layers.encoder_layer_3.mlp.0._packed_params._packed_params', 'encoder.layers.encoder_layer_3.mlp.3.scale', 'encoder.layers.encoder_layer_3.mlp.3.zero_point', 'encoder.layers.encoder_layer_3.mlp.3._packed_params.dtype', 'encoder.layers.encoder_layer_3.mlp.3._packed_params._packed_params', 'encoder.layers.encoder_layer_4.ln_1.weight', 'encoder.layers.encoder_layer_4.ln_1.bias', 'encoder.layers.encoder_layer_4.ln_1.scale', 'encoder.layers.encoder_layer_4.ln_1.zero_point', 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_4.ln_2.weight', 'encoder.layers.encoder_layer_4.ln_2.bias', 'encoder.layers.encoder_layer_4.ln_2.scale', 'encoder.layers.encoder_layer_4.ln_2.zero_point', 'encoder.layers.encoder_layer_4.mlp.0.scale', 'encoder.layers.encoder_layer_4.mlp.0.zero_point', 'encoder.layers.encoder_layer_4.mlp.0._packed_params.dtype', 'encoder.layers.encoder_layer_4.mlp.0._packed_params._packed_params', 'encoder.layers.encoder_layer_4.mlp.3.scale', 'encoder.layers.encoder_layer_4.mlp.3.zero_point', 'encoder.layers.encoder_layer_4.mlp.3._packed_params.dtype', 'encoder.layers.encoder_layer_4.mlp.3._packed_params._packed_params', 'encoder.layers.encoder_layer_5.ln_1.weight', 'encoder.layers.encoder_layer_5.ln_1.bias', 'encoder.layers.encoder_layer_5.ln_1.scale', 'encoder.layers.encoder_layer_5.ln_1.zero_point', 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_5.ln_2.weight', 'encoder.layers.encoder_layer_5.ln_2.bias', 'encoder.layers.encoder_layer_5.ln_2.scale', 'encoder.layers.encoder_layer_5.ln_2.zero_point', 'encoder.layers.encoder_layer_5.mlp.0.scale', 'encoder.layers.encoder_layer_5.mlp.0.zero_point', 'encoder.layers.encoder_layer_5.mlp.0._packed_params.dtype', 'encoder.layers.encoder_layer_5.mlp.0._packed_params._packed_params', 'encoder.layers.encoder_layer_5.mlp.3.scale', 'encoder.layers.encoder_layer_5.mlp.3.zero_point', 'encoder.layers.encoder_layer_5.mlp.3._packed_params.dtype', 'encoder.layers.encoder_layer_5.mlp.3._packed_params._packed_params', 'encoder.layers.encoder_layer_6.ln_1.weight', 'encoder.layers.encoder_layer_6.ln_1.bias', 'encoder.layers.encoder_layer_6.ln_1.scale', 'encoder.layers.encoder_layer_6.ln_1.zero_point', 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_6.ln_2.weight', 'encoder.layers.encoder_layer_6.ln_2.bias', 'encoder.layers.encoder_layer_6.ln_2.scale', 'encoder.layers.encoder_layer_6.ln_2.zero_point', 'encoder.layers.encoder_layer_6.mlp.0.scale', 'encoder.layers.encoder_layer_6.mlp.0.zero_point', 'encoder.layers.encoder_layer_6.mlp.0._packed_params.dtype', 'encoder.layers.encoder_layer_6.mlp.0._packed_params._packed_params', 'encoder.layers.encoder_layer_6.mlp.3.scale', 'encoder.layers.encoder_layer_6.mlp.3.zero_point', 'encoder.layers.encoder_layer_6.mlp.3._packed_params.dtype', 'encoder.layers.encoder_layer_6.mlp.3._packed_params._packed_params', 'encoder.layers.encoder_layer_7.ln_1.weight', 'encoder.layers.encoder_layer_7.ln_1.bias', 'encoder.layers.encoder_layer_7.ln_1.scale', 'encoder.layers.encoder_layer_7.ln_1.zero_point', 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_7.ln_2.weight', 'encoder.layers.encoder_layer_7.ln_2.bias', 'encoder.layers.encoder_layer_7.ln_2.scale', 'encoder.layers.encoder_layer_7.ln_2.zero_point', 'encoder.layers.encoder_layer_7.mlp.0.scale', 'encoder.layers.encoder_layer_7.mlp.0.zero_point', 'encoder.layers.encoder_layer_7.mlp.0._packed_params.dtype', 'encoder.layers.encoder_layer_7.mlp.0._packed_params._packed_params', 'encoder.layers.encoder_layer_7.mlp.3.scale', 'encoder.layers.encoder_layer_7.mlp.3.zero_point', 'encoder.layers.encoder_layer_7.mlp.3._packed_params.dtype', 'encoder.layers.encoder_layer_7.mlp.3._packed_params._packed_params', 'encoder.layers.encoder_layer_8.ln_1.weight', 'encoder.layers.encoder_layer_8.ln_1.bias', 'encoder.layers.encoder_layer_8.ln_1.scale', 'encoder.layers.encoder_layer_8.ln_1.zero_point', 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_8.ln_2.weight', 'encoder.layers.encoder_layer_8.ln_2.bias', 'encoder.layers.encoder_layer_8.ln_2.scale', 'encoder.layers.encoder_layer_8.ln_2.zero_point', 'encoder.layers.encoder_layer_8.mlp.0.scale', 'encoder.layers.encoder_layer_8.mlp.0.zero_point', 'encoder.layers.encoder_layer_8.mlp.0._packed_params.dtype', 'encoder.layers.encoder_layer_8.mlp.0._packed_params._packed_params', 'encoder.layers.encoder_layer_8.mlp.3.scale', 'encoder.layers.encoder_layer_8.mlp.3.zero_point', 'encoder.layers.encoder_layer_8.mlp.3._packed_params.dtype', 'encoder.layers.encoder_layer_8.mlp.3._packed_params._packed_params', 'encoder.layers.encoder_layer_9.ln_1.weight', 'encoder.layers.encoder_layer_9.ln_1.bias', 'encoder.layers.encoder_layer_9.ln_1.scale', 'encoder.layers.encoder_layer_9.ln_1.zero_point', 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_9.ln_2.weight', 'encoder.layers.encoder_layer_9.ln_2.bias', 'encoder.layers.encoder_layer_9.ln_2.scale', 'encoder.layers.encoder_layer_9.ln_2.zero_point', 'encoder.layers.encoder_layer_9.mlp.0.scale', 'encoder.layers.encoder_layer_9.mlp.0.zero_point', 'encoder.layers.encoder_layer_9.mlp.0._packed_params.dtype', 'encoder.layers.encoder_layer_9.mlp.0._packed_params._packed_params', 'encoder.layers.encoder_layer_9.mlp.3.scale', 'encoder.layers.encoder_layer_9.mlp.3.zero_point', 'encoder.layers.encoder_layer_9.mlp.3._packed_params.dtype', 'encoder.layers.encoder_layer_9.mlp.3._packed_params._packed_params', 'encoder.layers.encoder_layer_10.ln_1.weight', 'encoder.layers.encoder_layer_10.ln_1.bias', 'encoder.layers.encoder_layer_10.ln_1.scale', 'encoder.layers.encoder_layer_10.ln_1.zero_point', 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_10.ln_2.weight', 'encoder.layers.encoder_layer_10.ln_2.bias', 'encoder.layers.encoder_layer_10.ln_2.scale', 'encoder.layers.encoder_layer_10.ln_2.zero_point', 'encoder.layers.encoder_layer_10.mlp.0.scale', 'encoder.layers.encoder_layer_10.mlp.0.zero_point', 'encoder.layers.encoder_layer_10.mlp.0._packed_params.dtype', 'encoder.layers.encoder_layer_10.mlp.0._packed_params._packed_params', 'encoder.layers.encoder_layer_10.mlp.3.scale', 'encoder.layers.encoder_layer_10.mlp.3.zero_point', 'encoder.layers.encoder_layer_10.mlp.3._packed_params.dtype', 'encoder.layers.encoder_layer_10.mlp.3._packed_params._packed_params', 'encoder.layers.encoder_layer_11.ln_1.weight', 'encoder.layers.encoder_layer_11.ln_1.bias', 'encoder.layers.encoder_layer_11.ln_1.scale', 'encoder.layers.encoder_layer_11.ln_1.zero_point', 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight', 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias', 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight', 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias', 'encoder.layers.encoder_layer_11.ln_2.weight', 'encoder.layers.encoder_layer_11.ln_2.bias', 'encoder.layers.encoder_layer_11.ln_2.scale', 'encoder.layers.encoder_layer_11.ln_2.zero_point', 'encoder.layers.encoder_layer_11.mlp.0.scale', 'encoder.layers.encoder_layer_11.mlp.0.zero_point', 'encoder.layers.encoder_layer_11.mlp.0._packed_params.dtype', 'encoder.layers.encoder_layer_11.mlp.0._packed_params._packed_params', 'encoder.layers.encoder_layer_11.mlp.3.scale', 'encoder.layers.encoder_layer_11.mlp.3.zero_point', 'encoder.layers.encoder_layer_11.mlp.3._packed_params.dtype', 'encoder.layers.encoder_layer_11.mlp.3._packed_params._packed_params', 'encoder.ln.weight', 'encoder.ln.bias', 'encoder.ln.scale', 'encoder.ln.zero_point', 'heads.head.scale', 'heads.head.zero_point', 'heads.head._packed_params.dtype', 'heads.head._packed_params._packed_params'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['encoder_layers_encoder_layer_1_scale_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0020, -0.0047,  0.0108, -0.0094, -0.0087,  0.0128,  0.0182,  0.0296,\n",
       "         0.0182, -0.0007,  0.0148,  0.0249,  0.0081,  0.0141, -0.0061,  0.0020,\n",
       "        -0.0067, -0.0040,  0.0168,  0.0094, -0.0067, -0.0067,  0.0020,  0.0222,\n",
       "         0.0081, -0.0168, -0.0034,  0.0108, -0.0135, -0.0108, -0.0188, -0.0007,\n",
       "        -0.0040, -0.0081,  0.0309,  0.0323,  0.0168, -0.0128, -0.0161,  0.0155,\n",
       "        -0.0020, -0.0377, -0.0121,  0.0094, -0.0148, -0.0047, -0.0108,  0.0155,\n",
       "        -0.0074, -0.0202,  0.0061,  0.0087, -0.0067, -0.0457, -0.0605, -0.0148,\n",
       "        -0.0242, -0.0531, -0.0128,  0.0128, -0.0135, -0.0040, -0.0094,  0.0175,\n",
       "         0.0155, -0.0094,  0.0020, -0.0027, -0.0087, -0.0309, -0.0336,  0.0168,\n",
       "         0.0101, -0.0148,  0.0229,  0.0336, -0.0027,  0.0054, -0.0054,  0.0161,\n",
       "         0.0242,  0.0034,  0.0114, -0.0040,  0.0074,  0.0175,  0.0269,  0.0437,\n",
       "         0.0114, -0.0034,  0.0256,  0.0081, -0.0121,  0.0074, -0.0040,  0.0087,\n",
       "         0.0040, -0.0175, -0.0202, -0.0269, -0.0040,  0.0249,  0.0175, -0.0222,\n",
       "        -0.0585, -0.0478, -0.0047, -0.0161, -0.0202,  0.0222,  0.0034,  0.0047,\n",
       "        -0.0101, -0.0316, -0.0188, -0.0141,  0.0007,  0.0229,  0.0135, -0.0108,\n",
       "        -0.0256, -0.0148,  0.0067, -0.0020,  0.0000,  0.0370,  0.0047,  0.0188,\n",
       "        -0.0114, -0.0289, -0.0081, -0.0040, -0.0087,  0.0081,  0.0202,  0.0350,\n",
       "         0.0235, -0.0209, -0.0256, -0.0209, -0.0087,  0.0074, -0.0175,  0.0074,\n",
       "        -0.0007, -0.0202, -0.0087, -0.0040,  0.0034,  0.0269,  0.0330,  0.0404,\n",
       "         0.0161, -0.0357, -0.0336, -0.0188, -0.0168,  0.0020, -0.0155,  0.0108,\n",
       "         0.0094, -0.0195, -0.0101,  0.0020,  0.0330,  0.0471,  0.0168, -0.0020,\n",
       "         0.0135,  0.0161,  0.0182, -0.0081, -0.0128,  0.0283,  0.0155,  0.0242,\n",
       "         0.0148, -0.0155, -0.0067,  0.0000,  0.0155,  0.0067, -0.0289, -0.0404,\n",
       "        -0.0034,  0.0323,  0.0101, -0.0471, -0.0437,  0.0195,  0.0175,  0.0182,\n",
       "         0.0370,  0.0114,  0.0161,  0.0081,  0.0135,  0.0101,  0.0047, -0.0101,\n",
       "        -0.0235, -0.0121, -0.0013, -0.0350, -0.0316,  0.0188,  0.0141,  0.0121,\n",
       "         0.0357,  0.0000,  0.0007, -0.0087,  0.0000,  0.0188,  0.0229, -0.0067,\n",
       "        -0.0531, -0.0457, -0.0020, -0.0034, -0.0128,  0.0094, -0.0074, -0.0061,\n",
       "         0.0256, -0.0108, -0.0067, -0.0094,  0.0128,  0.0242,  0.0141, -0.0094,\n",
       "        -0.0262, -0.0148,  0.0195,  0.0168,  0.0000,  0.0074, -0.0067, -0.0013,\n",
       "         0.0061, -0.0188,  0.0020,  0.0074,  0.0235,  0.0222, -0.0013,  0.0013,\n",
       "         0.0108,  0.0175,  0.0276,  0.0067, -0.0114,  0.0013, -0.0094, -0.0007,\n",
       "         0.0034, -0.0087,  0.0101, -0.0094, -0.0175,  0.0101,  0.0188,  0.0363,\n",
       "         0.0249,  0.0034,  0.0249,  0.0309,  0.0148,  0.0135, -0.0081, -0.0007,\n",
       "        -0.0074, -0.0067,  0.0215,  0.0175, -0.0121, -0.0148, -0.0013,  0.0303,\n",
       "         0.0108, -0.0215,  0.0040,  0.0114, -0.0141, -0.0168, -0.0242, -0.0054,\n",
       "        -0.0047, -0.0121,  0.0357,  0.0424,  0.0094, -0.0242, -0.0296,  0.0202,\n",
       "        -0.0034, -0.0478, -0.0087,  0.0128, -0.0101, -0.0121, -0.0161,  0.0108,\n",
       "        -0.0034, -0.0303,  0.0040,  0.0148, -0.0161, -0.0673, -0.0780, -0.0161,\n",
       "        -0.0229, -0.0558,  0.0007,  0.0269, -0.0074, -0.0094, -0.0128,  0.0087,\n",
       "         0.0262, -0.0114,  0.0034,  0.0054, -0.0094, -0.0276, -0.0235,  0.0410,\n",
       "         0.0377,  0.0081,  0.0605,  0.0612,  0.0128,  0.0094, -0.0061,  0.0067,\n",
       "         0.0410,  0.0074,  0.0195,  0.0121,  0.0182,  0.0444,  0.0565,  0.0753,\n",
       "         0.0323,  0.0161,  0.0599,  0.0276,  0.0007,  0.0121, -0.0108, -0.0067,\n",
       "         0.0155, -0.0188, -0.0135, -0.0101,  0.0074,  0.0484,  0.0262, -0.0296,\n",
       "        -0.0861, -0.0592,  0.0087, -0.0101, -0.0074,  0.0276, -0.0007, -0.0114,\n",
       "        -0.0054, -0.0363, -0.0222, -0.0081,  0.0034,  0.0303,  0.0054, -0.0336,\n",
       "        -0.0511, -0.0269,  0.0148, -0.0027,  0.0148,  0.0491,  0.0061,  0.0074,\n",
       "        -0.0101, -0.0323, -0.0067, -0.0007, -0.0128,  0.0020,  0.0081,  0.0269,\n",
       "         0.0188, -0.0363, -0.0343, -0.0269, -0.0027,  0.0141, -0.0209, -0.0054,\n",
       "         0.0054, -0.0235, -0.0101, -0.0054, -0.0054,  0.0202,  0.0249,  0.0390,\n",
       "         0.0161, -0.0417, -0.0343, -0.0175, -0.0027,  0.0094, -0.0215, -0.0034,\n",
       "         0.0168, -0.0256, -0.0155, -0.0007,  0.0283,  0.0444,  0.0054, -0.0114,\n",
       "         0.0215,  0.0410,  0.0505,  0.0034, -0.0013,  0.0370,  0.0148,  0.0161,\n",
       "         0.0209, -0.0249, -0.0182, -0.0141, -0.0040, -0.0081, -0.0552, -0.0619,\n",
       "         0.0034,  0.0619,  0.0457, -0.0444, -0.0484,  0.0235,  0.0202,  0.0128,\n",
       "         0.0464,  0.0061,  0.0020, -0.0061, -0.0135, -0.0067, -0.0121, -0.0215,\n",
       "        -0.0262,  0.0007,  0.0175, -0.0377, -0.0377,  0.0209,  0.0141,  0.0061,\n",
       "         0.0390, -0.0101, -0.0128, -0.0229, -0.0235,  0.0054,  0.0175, -0.0141,\n",
       "        -0.0713, -0.0558,  0.0061, -0.0040, -0.0101,  0.0101, -0.0128, -0.0229,\n",
       "         0.0303, -0.0168, -0.0168, -0.0195, -0.0047,  0.0195,  0.0161, -0.0128,\n",
       "        -0.0330, -0.0128,  0.0397,  0.0296,  0.0094,  0.0121, -0.0081, -0.0101,\n",
       "         0.0000, -0.0316, -0.0141, -0.0047,  0.0081,  0.0114, -0.0074, -0.0047,\n",
       "         0.0067,  0.0235,  0.0437,  0.0148, -0.0061, -0.0013, -0.0161, -0.0067,\n",
       "         0.0000, -0.0081, -0.0013, -0.0094, -0.0229, -0.0027,  0.0013,  0.0108,\n",
       "         0.0061, -0.0061,  0.0087,  0.0121,  0.0061,  0.0101, -0.0067, -0.0034,\n",
       "        -0.0074, -0.0054,  0.0061,  0.0087, -0.0175, -0.0135, -0.0061,  0.0128,\n",
       "         0.0040, -0.0128,  0.0020,  0.0000, -0.0108, -0.0135, -0.0135, -0.0067,\n",
       "        -0.0027, -0.0094,  0.0155,  0.0256,  0.0013, -0.0148, -0.0148,  0.0135,\n",
       "         0.0027, -0.0262, -0.0020,  0.0007, -0.0094, -0.0121, -0.0121,  0.0034,\n",
       "        -0.0047, -0.0209, -0.0020,  0.0121, -0.0061, -0.0309, -0.0383, -0.0047,\n",
       "        -0.0087, -0.0316, -0.0007,  0.0087, -0.0047, -0.0081, -0.0101, -0.0007,\n",
       "         0.0195, -0.0047,  0.0000,  0.0081, -0.0034, -0.0101, -0.0121,  0.0256,\n",
       "         0.0269,  0.0094,  0.0357,  0.0309,  0.0027, -0.0013, -0.0101, -0.0020,\n",
       "         0.0276,  0.0067,  0.0114,  0.0128,  0.0074,  0.0256,  0.0289,  0.0437,\n",
       "         0.0222,  0.0114,  0.0370,  0.0087, -0.0081, -0.0027, -0.0141, -0.0155,\n",
       "         0.0108, -0.0034, -0.0027,  0.0020,  0.0027,  0.0229,  0.0061, -0.0256,\n",
       "        -0.0545, -0.0343,  0.0061, -0.0128, -0.0094,  0.0087, -0.0061, -0.0188,\n",
       "         0.0027, -0.0128, -0.0047,  0.0040, -0.0013,  0.0074, -0.0114, -0.0363,\n",
       "        -0.0383, -0.0182,  0.0128, -0.0047,  0.0087,  0.0262, -0.0034, -0.0081,\n",
       "        -0.0054, -0.0087,  0.0074,  0.0148, -0.0128, -0.0114, -0.0121,  0.0027,\n",
       "         0.0020, -0.0235, -0.0161, -0.0148,  0.0040,  0.0027, -0.0195, -0.0135,\n",
       "         0.0074, -0.0034,  0.0013,  0.0061, -0.0081,  0.0054,  0.0081,  0.0155,\n",
       "         0.0047, -0.0249, -0.0121, -0.0027,  0.0027, -0.0027, -0.0222, -0.0135,\n",
       "         0.0074, -0.0128, -0.0067,  0.0054,  0.0135,  0.0283,  0.0061, -0.0061,\n",
       "         0.0229,  0.0390,  0.0431,  0.0081,  0.0040,  0.0202,  0.0027, -0.0013,\n",
       "         0.0087, -0.0148, -0.0121, -0.0027, -0.0020,  0.0034, -0.0182, -0.0202,\n",
       "         0.0235,  0.0612,  0.0451, -0.0202, -0.0195,  0.0148,  0.0081, -0.0040,\n",
       "         0.0256,  0.0034,  0.0020,  0.0020, -0.0067,  0.0020,  0.0108,  0.0114,\n",
       "         0.0047,  0.0188,  0.0276, -0.0114, -0.0148,  0.0141,  0.0074, -0.0034,\n",
       "         0.0215, -0.0094, -0.0141, -0.0101, -0.0175,  0.0020,  0.0175,  0.0040,\n",
       "        -0.0309, -0.0209,  0.0188,  0.0047, -0.0013,  0.0067, -0.0101, -0.0215,\n",
       "         0.0188, -0.0114, -0.0135, -0.0061, -0.0067,  0.0094,  0.0081, -0.0027,\n",
       "        -0.0121,  0.0034,  0.0323,  0.0195,  0.0114,  0.0087, -0.0034, -0.0081,\n",
       "        -0.0027, -0.0229, -0.0161, -0.0040, -0.0007,  0.0027, -0.0121, -0.0074,\n",
       "         0.0061,  0.0141,  0.0215, -0.0007, -0.0067,  0.0007, -0.0114, -0.0074],\n",
       "       size=(768,), dtype=torch.qint8,\n",
       "       quantization_scheme=torch.per_tensor_affine, scale=0.0006726672290824354,\n",
       "       zero_point=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv_proj.weight()[-1].data.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, t in T.items():\n",
    "    print(key, 'time:', t, 'acc', accuracy[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "date_time = datetime.datetime.now()\n",
    "date_time\n",
    "with open(f'results{date_time}.txt', 'w+') as fopen:\n",
    "    for key, t in T.items():\n",
    "        fopen.write(f\"{key}, time:, {t}, acc, {accuracy[key]}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
