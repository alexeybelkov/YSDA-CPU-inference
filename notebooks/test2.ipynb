{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "          aten::linear        19.75%     433.000us       100.00%       2.192ms       2.192ms             1  \n",
      "               aten::t         1.14%      25.000us         2.74%      60.000us      60.000us             1  \n",
      "       aten::transpose         1.37%      30.000us         1.60%      35.000us      35.000us             1  \n",
      "      aten::as_strided         0.23%       5.000us         0.23%       5.000us       5.000us             1  \n",
      "          aten::matmul         6.25%     137.000us        77.51%       1.699ms       1.699ms             1  \n",
      "              aten::mm        70.99%       1.556ms        71.26%       1.562ms       1.562ms             1  \n",
      "    aten::resolve_conj         0.27%       6.000us         0.27%       6.000us       3.000us             2  \n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.192ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-11-23 19:24:00 81240:81240 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2023-11-23 19:24:00 81240:81240 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2023-11-23 19:24:00 81240:81240 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(256, 512)\n",
    "linear = nn.Linear(512, 256, bias=False).eval()\n",
    "linear.weight.requires_grad = False\n",
    "# linear.bias.requires_grad = False\n",
    "\n",
    "with torch.inference_mode():\n",
    "    with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "        linear(x)\n",
    "print(prof.key_averages().table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit = torch.jit.script(linear)\n",
    "torch.jit.save(jit, 'linear.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "        aten::quantize_per_tensor         8.48%      89.000us         9.05%      95.000us      95.000us             1  \n",
      "                       aten::item         1.05%      11.000us         1.24%      13.000us       3.250us             4  \n",
      "        aten::_local_scalar_dense         0.19%       2.000us         0.19%       2.000us       0.500us             4  \n",
      "                quantized::linear        81.43%     855.000us        86.57%     909.000us     909.000us             1  \n",
      "    aten::_empty_affine_quantized         2.57%      27.000us         2.57%      27.000us      27.000us             1  \n",
      "                    aten::q_scale         0.10%       1.000us         0.10%       1.000us       1.000us             1  \n",
      "               aten::q_zero_point         0.00%       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                    aten::resize_         1.71%      18.000us         1.71%      18.000us      18.000us             1  \n",
      "                      aten::empty         1.33%      14.000us         1.33%      14.000us       7.000us             2  \n",
      "                 aten::dequantize         3.14%      33.000us         3.71%      39.000us      39.000us             1  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.050ms\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, input : torch.Tensor) -> torch.Tensor:\n",
      "    input_1 = input\n",
      "    _input_scale_0 = self._input_scale_0\n",
      "    _input_zero_point_0 = self._input_zero_point_0\n",
      "    quantize_per_tensor = torch.quantize_per_tensor(input_1, _input_scale_0, _input_zero_point_0, torch.quint8);  input_1 = _input_scale_0 = _input_zero_point_0 = None\n",
      "    _packed_weight_0 = self._packed_weight_0\n",
      "    _scale_1 = self._scale_1\n",
      "    _zero_point_1 = self._zero_point_1\n",
      "    linear = torch.ops.quantized.linear(quantize_per_tensor, _packed_weight_0, _scale_1, _zero_point_1);  quantize_per_tensor = _packed_weight_0 = _scale_1 = _zero_point_1 = None\n",
      "    dequantize_2 = linear.dequantize();  linear = None\n",
      "    return dequantize_2\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexey/.local/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
      "  torch.has_cuda,\n",
      "/home/alexey/.local/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'\n",
      "  torch.has_cudnn,\n",
      "/home/alexey/.local/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  torch.has_mps,\n",
      "/home/alexey/.local/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'\n",
      "  torch.has_mkldnn,\n",
      "/home/alexey/.local/lib/python3.10/site-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "/home/alexey/.local/lib/python3.10/site-packages/torch/fx/graph.py:1377: UserWarning: Node _packed_weight_0 target _packed_weight_0 _packed_weight_0 of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target\n",
      "  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '\n",
      "STAGE:2023-11-23 19:24:02 81240:81240 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2023-11-23 19:24:02 81240:81240 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2023-11-23 19:24:02 81240:81240 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "from torch.ao.quantization import get_default_qconfig\n",
    "from torch.ao.quantization.quantize_fx import prepare_fx, convert_fx\n",
    "from torch.ao.quantization import QConfigMapping\n",
    "\n",
    "with torch.inference_mode():\n",
    "    torch.backends.quantized.engine = 'x86'\n",
    "    qconfig = get_default_qconfig('x86')\n",
    "    qconfig_mapping = QConfigMapping().set_global(qconfig)\n",
    "    example_inputs = torch.randn_like(x)\n",
    "    prepared_model = prepare_fx(linear, qconfig_mapping, example_inputs)\n",
    "    for _ in range(16):\n",
    "        prepared_model(torch.randn_like(x))\n",
    "\n",
    "    quantized_model = convert_fx(prepared_model)\n",
    "\n",
    "    with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "        quantized_model(x)\n",
    "\n",
    "print(prof.key_averages().table())\n",
    "print(quantized_model.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexey/.local/lib/python3.10/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "jit = torch.jit.script(quantized_model)\n",
    "torch.jit.save(jit, 'x86_linear.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "        aten::quantize_per_tensor        49.00%     415.000us        50.06%     424.000us     424.000us             1  \n",
      "                       aten::item         1.06%       9.000us         1.53%      13.000us       3.250us             4  \n",
      "        aten::_local_scalar_dense         0.47%       4.000us         0.47%       4.000us       1.000us             4  \n",
      "                quantized::linear        46.04%     390.000us        47.70%     404.000us     404.000us             1  \n",
      "    aten::_empty_affine_quantized         0.59%       5.000us         0.59%       5.000us       5.000us             1  \n",
      "                    aten::q_scale         0.00%       0.000us         0.00%       0.000us       0.000us             1  \n",
      "               aten::q_zero_point         0.00%       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                    aten::resize_         0.59%       5.000us         0.59%       5.000us       5.000us             1  \n",
      "                      aten::empty         0.71%       6.000us         0.71%       6.000us       3.000us             2  \n",
      "                 aten::dequantize         1.53%      13.000us         1.77%      15.000us      15.000us             1  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 847.000us\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, input : torch.Tensor) -> torch.Tensor:\n",
      "    input_1 = input\n",
      "    _input_scale_0 = self._input_scale_0\n",
      "    _input_zero_point_0 = self._input_zero_point_0\n",
      "    quantize_per_tensor = torch.quantize_per_tensor(input_1, _input_scale_0, _input_zero_point_0, torch.quint8);  input_1 = _input_scale_0 = _input_zero_point_0 = None\n",
      "    _packed_weight_0 = self._packed_weight_0\n",
      "    _scale_1 = self._scale_1\n",
      "    _zero_point_1 = self._zero_point_1\n",
      "    linear = torch.ops.quantized.linear(quantize_per_tensor, _packed_weight_0, _scale_1, _zero_point_1);  quantize_per_tensor = _packed_weight_0 = _scale_1 = _zero_point_1 = None\n",
      "    dequantize_2 = linear.dequantize();  linear = None\n",
      "    return dequantize_2\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-11-23 19:24:05 81240:81240 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2023-11-23 19:24:05 81240:81240 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2023-11-23 19:24:05 81240:81240 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "from torch.ao.quantization import get_default_qconfig\n",
    "from torch.ao.quantization.quantize_fx import prepare_fx, convert_fx\n",
    "from torch.ao.quantization import QConfigMapping\n",
    "\n",
    "with torch.inference_mode():\n",
    "    torch.backends.quantized.engine = 'fbgemm'\n",
    "    qconfig = get_default_qconfig('fbgemm')\n",
    "    qconfig_mapping = QConfigMapping().set_global(qconfig)\n",
    "    example_inputs = torch.randn_like(x)\n",
    "    prepared_model = prepare_fx(linear, qconfig_mapping, example_inputs)\n",
    "    for _ in range(16):\n",
    "        prepared_model(torch.randn_like(x))\n",
    "\n",
    "    quantized_model = convert_fx(prepared_model)\n",
    "\n",
    "    with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "        quantized_model(x)\n",
    "\n",
    "print(prof.key_averages().table())\n",
    "print(quantized_model.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit = torch.jit.script(quantized_model)\n",
    "torch.jit.save(jit, 'fbgemm_linear.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "        aten::quantize_per_tensor        85.14%       3.369ms        85.39%       3.379ms       3.379ms             1  \n",
      "                       aten::item         0.38%      15.000us         0.51%      20.000us       5.000us             4  \n",
      "        aten::_local_scalar_dense         0.15%       6.000us         0.15%       6.000us       1.500us             4  \n",
      "                quantized::linear        12.56%     497.000us        13.19%     522.000us     522.000us             1  \n",
      "    aten::_empty_affine_quantized         0.28%      11.000us         0.28%      11.000us      11.000us             1  \n",
      "                    aten::q_scale         0.00%       0.000us         0.00%       0.000us       0.000us             1  \n",
      "               aten::q_zero_point         0.00%       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                    aten::resize_         0.18%       7.000us         0.18%       7.000us       7.000us             1  \n",
      "                      aten::empty         0.30%      12.000us         0.30%      12.000us       6.000us             2  \n",
      "                 aten::dequantize         1.01%      40.000us         1.14%      45.000us      45.000us             1  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 3.957ms\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, input : torch.Tensor) -> torch.Tensor:\n",
      "    input_1 = input\n",
      "    _input_scale_0 = self._input_scale_0\n",
      "    _input_zero_point_0 = self._input_zero_point_0\n",
      "    quantize_per_tensor = torch.quantize_per_tensor(input_1, _input_scale_0, _input_zero_point_0, torch.quint8);  input_1 = _input_scale_0 = _input_zero_point_0 = None\n",
      "    _packed_weight_0 = self._packed_weight_0\n",
      "    _scale_1 = self._scale_1\n",
      "    _zero_point_1 = self._zero_point_1\n",
      "    linear = torch.ops.quantized.linear(quantize_per_tensor, _packed_weight_0, _scale_1, _zero_point_1);  quantize_per_tensor = _packed_weight_0 = _scale_1 = _zero_point_1 = None\n",
      "    dequantize_2 = linear.dequantize();  linear = None\n",
      "    return dequantize_2\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-11-20 19:58:42 112085:112085 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2023-11-20 19:58:42 112085:112085 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2023-11-20 19:58:42 112085:112085 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "from torch.ao.quantization import get_default_qconfig\n",
    "from torch.ao.quantization.quantize_fx import prepare_fx, convert_fx\n",
    "from torch.ao.quantization import QConfigMapping\n",
    "\n",
    "with torch.inference_mode():\n",
    "\n",
    "    qconfig = get_default_qconfig('fbgemm')\n",
    "    qconfig_mapping = QConfigMapping().set_global(qconfig)\n",
    "    example_inputs = torch.randn_like(x)\n",
    "    prepared_model = prepare_fx(linear, qconfig_mapping, example_inputs)\n",
    "    for _ in range(16):\n",
    "        prepared_model(torch.randn_like(x))\n",
    "\n",
    "    quantized_model = convert_fx(prepared_model)\n",
    "\n",
    "    with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "        quantized_model(x)\n",
    "\n",
    "print(prof.key_averages().table())\n",
    "print(quantized_model.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexey/.local/lib/python3.10/site-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "jit = torch.jit.script(quantized_model)\n",
    "# torch.jit.save(jit, 'fbgemm_linear.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%self : __torch__.torch.fx.graph_module.GraphModule,\n",
      "      %input.1 : Tensor):\n",
      "  %8 : int = prim::Constant[value=13]() # <eval_with_key>.15:8:98\n",
      "  %_input_scale_0.1 : Tensor = prim::GetAttr[name=\"_input_scale_0\"](%self)\n",
      "  %_input_zero_point_0.1 : Tensor = prim::GetAttr[name=\"_input_zero_point_0\"](%self)\n",
      "  %quantize_per_tensor.1 : Tensor = aten::quantize_per_tensor(%input.1, %_input_scale_0.1, %_input_zero_point_0.1, %8) # <eval_with_key>.15:8:26\n",
      "  %_packed_weight_0.1 : __torch__.torch.classes.quantized.LinearPackedParamsBase = prim::GetAttr[name=\"_packed_weight_0\"](%self)\n",
      "  %_scale_1.1 : Tensor = prim::GetAttr[name=\"_scale_1\"](%self)\n",
      "  %_zero_point_1.1 : Tensor = prim::GetAttr[name=\"_zero_point_1\"](%self)\n",
      "  %21 : float = aten::FloatImplicit(%_scale_1.1) # <eval_with_key>.15:12:13\n",
      "  %22 : int = aten::IntImplicit(%_zero_point_1.1) # <eval_with_key>.15:12:13\n",
      "  %linear.1 : Tensor = quantized::linear(%quantize_per_tensor.1, %_packed_weight_0.1, %21, %22) # <eval_with_key>.15:12:13\n",
      "  %dequantize_2.1 : Tensor = aten::dequantize(%linear.1) # <eval_with_key>.15:13:19\n",
      "  return (%dequantize_2.1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(jit.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "        aten::quantize_per_tensor         0.23%      60.000us         0.26%      68.000us      68.000us             1  \n",
      "                       aten::item         0.03%       9.000us         0.04%      11.000us       2.750us             4  \n",
      "        aten::_local_scalar_dense         0.01%       2.000us         0.01%       2.000us       0.500us             4  \n",
      "                quantized::conv2d        35.61%       9.285ms        36.00%       9.387ms       9.387ms             1  \n",
      "                 aten::contiguous         0.01%       2.000us         0.36%      95.000us      95.000us             1  \n",
      "                      aten::clone         0.33%      87.000us         0.36%      93.000us      93.000us             1  \n",
      "                    aten::qscheme         0.00%       0.000us         0.00%       0.000us       0.000us             3  \n",
      "               aten::q_zero_point         0.00%       0.000us         0.00%       0.000us       0.000us             2  \n",
      "                    aten::q_scale         0.00%       0.000us         0.00%       0.000us       0.000us             2  \n",
      "    aten::_empty_affine_quantized         0.03%       8.000us         0.03%       8.000us       4.000us             2  \n",
      "                      aten::empty         0.06%      16.000us         0.06%      16.000us       8.000us             2  \n",
      "                 aten::dequantize        63.68%      16.603ms        63.72%      16.614ms      16.614ms             1  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 26.072ms\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, input : torch.Tensor) -> torch.Tensor:\n",
      "    input_1 = input\n",
      "    _input_scale_0 = self._input_scale_0\n",
      "    _input_zero_point_0 = self._input_zero_point_0\n",
      "    quantize_per_tensor = torch.quantize_per_tensor(input_1, _input_scale_0, _input_zero_point_0, torch.quint8);  input_1 = _input_scale_0 = _input_zero_point_0 = None\n",
      "    _packed_weight_0 = self._packed_weight_0\n",
      "    _scale_1 = self._scale_1\n",
      "    _zero_point_1 = self._zero_point_1\n",
      "    conv2d = torch.ops.quantized.conv2d(quantize_per_tensor, _packed_weight_0, _scale_1, _zero_point_1);  quantize_per_tensor = _packed_weight_0 = _scale_1 = _zero_point_1 = None\n",
      "    dequantize_2 = conv2d.dequantize();  conv2d = None\n",
      "    return dequantize_2\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-11-20 19:58:43 112085:112085 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2023-11-20 19:58:43 112085:112085 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2023-11-20 19:58:43 112085:112085 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "from torch.ao.quantization import get_default_qconfig\n",
    "from torch.ao.quantization.quantize_fx import prepare_fx, convert_fx\n",
    "from torch.ao.quantization import QConfigMapping\n",
    "\n",
    "conv2d = nn.Conv2d(16, 8, 3)\n",
    "image = torch.randn(1, 16, 64, 64)\n",
    "\n",
    "with torch.inference_mode():\n",
    "\n",
    "    qconfig = get_default_qconfig('fbgemm')\n",
    "    qconfig_mapping = QConfigMapping().set_global(qconfig)\n",
    "    example_inputs = torch.randn_like(image)\n",
    "    prepared_model = prepare_fx(conv2d, qconfig_mapping, example_inputs)\n",
    "    for _ in range(16):\n",
    "        prepared_model(torch.randn_like(image))\n",
    "\n",
    "    quantized_model = convert_fx(prepared_model)\n",
    "\n",
    "    with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "        quantized_model(image)\n",
    "\n",
    "print(prof.key_averages().table())\n",
    "print(quantized_model.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
